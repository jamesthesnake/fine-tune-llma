{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daa8f33c-3758-4a65-a32d-59c2d7970cb2",
   "metadata": {},
   "source": [
    "<!-- Banner Image -->\n",
    "<img src=\"https://uohmivykqgnnbiouffke.supabase.co/storage/v1/object/public/landingpage/brevdevnotebooks.png\" width=\"100%\">\n",
    "\n",
    "<!-- Links -->\n",
    "<center>\n",
    "  <a href=\"https://console.brev.dev\" style=\"color: #06b6d4;\">Console</a> â€¢\n",
    "  <a href=\"https://brev.dev\" style=\"color: #06b6d4;\">Docs</a> â€¢\n",
    "  <a href=\"/\" style=\"color: #06b6d4;\">Templates</a> â€¢\n",
    "  <a href=\"https://discord.gg/NVDyv7TUgJ\" style=\"color: #06b6d4;\">Discord</a>\n",
    "</center>\n",
    "\n",
    "# Run Llama 2 with Brev using Verb ðŸ¤™ \n",
    "## We show you how easy it is to launch and run Llama 2 with Brev, on Verb!!\n",
    "\n",
    "In this guide, we show you how you can run Llama 2 with Brev using the new Verb containers! \n",
    "\n",
    "If you're looking for a fine-tuning guide, check out our [Llama 2 fine-tuning post](/blog/fine-tuning-llama-2).\n",
    "\n",
    "## To get started, click [here](http://console.brev.dev/environment/new) to create a new Brev instance. \n",
    "\n",
    "An A10G should work fine, and you can always scale up/down your instance from your instance settings page.\n",
    "\n",
    "## Build your Verb container.\n",
    "\n",
    "Once you've checked out your machine and landed in your instance page, select the specs you'd like (Python, CUDA, etc.) and click the \"Build\" button to build your Verb container. Give this a few minutes.\n",
    "\n",
    "## Open your new Brev Notebook or Machine. \n",
    "\n",
    "Once the Verb container is finished loading, click the 'Notebook' button on the top right of your screen once it illuminates. You will be taken to a Jupyter Lab environment. Under \"Other\" (in the Launcher), click \"Terminal\". Run the following commands. *Note: you can also ssh into the development environment and run the commands below from there by running `brev open [your-machine-name]` (to enter via VSCode) or `brev shell [your-machine-name]` (to enter via shell). Note that for these, you will need to have the Brev CLI installed; you can install it [here](https://brev.dev/docs/reference/brev-cli#installation-instructions).*\n",
    "\n",
    "```\n",
    "git clone https://github.com/facebookresearch/llama.git\n",
    "bash llama/download.sh\n",
    "```\n",
    "\n",
    "This will prompt you to enter the URL you got sent by Meta in an email. If you haven't signed up, do it [here](https://ai.meta.com/llama/). They are surprisingly quick at sending you the email!\n",
    "\n",
    "## Play with Llama.\n",
    "Run the cells below.\n",
    "Happy LLMing!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c47dd-0e69-4902-ae5e-8b660d6a2446",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch fire fairscale sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da4bba9-5b6e-48fb-8e82-8bd9d6a59da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/root/llama/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac496c88-af66-489e-bbdb-cbc75f9389db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "> initializing ddp with size 1\n",
      "> initializing pipeline with size 1\n",
      "Loaded in 106.60 seconds\n",
      "I believe the meaning of life is\n",
      "> to be happy. I believe we are all born with the potential to be happy. The meaning of life is to be happy, but the way to get there is not always easy.\n",
      "The meaning of life is to be happy. It is not always easy to be happy, but it is possible. I believe that\n",
      "\n",
      "==================================\n",
      "\n",
      "Simply put, the theory of relativity states that \n",
      "> 1) time, space, and mass are relative, and 2) the speed of light is constant, regardless of the relative motion of the observer.\n",
      "Letâ€™s look at the first point first.\n",
      "Relative Time and Space\n",
      "The theory of relativity is built on the idea that time and space are relative\n",
      "\n",
      "==================================\n",
      "\n",
      "A brief message congratulating the team on the launch:\n",
      "\n",
      "        Hi everyone,\n",
      "        \n",
      "        I just \n",
      "> wanted to say a big congratulations to the team on the launch of the new website.\n",
      "\n",
      "        I think it looks fantastic and I'm sure it will be a huge success.\n",
      "\n",
      "        I look forward to working with you all on the next project.\n",
      "\n",
      "        Best wishes\n",
      "\n",
      "\n",
      "\n",
      "==================================\n",
      "\n",
      "Translate English to French:\n",
      "        \n",
      "        sea otter => loutre de mer\n",
      "        peppermint => menthe poivrÃ©e\n",
      "        plush girafe => girafe peluche\n",
      "        cheese =>\n",
      "> fromage\n",
      "        fish => poisson\n",
      "        giraffe => girafe\n",
      "        elephant => Ã©lÃ©phant\n",
      "        cat => chat\n",
      "        sheep => mouton\n",
      "        tiger => tigre\n",
      "        zebra => zÃ¨bre\n",
      "        turtle => tortue\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the 7B completion model:\n",
    "\n",
    "!torchrun --nproc_per_node 1 example_text_completion.py \\\n",
    "    --ckpt_dir llama-2-7b/ \\\n",
    "    --tokenizer_path tokenizer.model \\\n",
    "    --max_seq_len 128 --max_batch_size 4\n",
    "\n",
    "# to change the model inputs, you can look at example_text_completion.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c8357-70b6-4c05-887a-5156c2afe365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the 7B chat model:\n",
    "\n",
    "!torchrun --nproc_per_node 1 example_chat_completion.py \\\n",
    "    --ckpt_dir llama-2-7b-chat/ \\\n",
    "    --tokenizer_path tokenizer.model \\\n",
    "    --max_seq_len 512 --max_batch_size 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
